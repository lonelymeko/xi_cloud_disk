# 文件夹下载技术方案

## 问题分析

**核心问题：** 文件夹下载不能像单文件那样直接返回 OSS 链接，必须由服务器处理。

### 为什么不能直接用 OSS 链接？

1. **文件分散：** 文件夹中的文件分散在 OSS 的不同位置
2. **目录结构：** 需要保持文件夹的层级结构
3. **批量操作：** 需要将多个文件打包成一个压缩包
4. **权限验证：** 需要验证用户对文件夹中所有文件的访问权限

---

## 方案对比

### 方案 1：同步打包下载（简单但性能差）

**流程：**
```
用户请求 → 服务器递归查询文件列表 → 从 OSS 下载所有文件 
→ 服务器打包成 ZIP → 返回给用户
```

**优点：**
- ✅ 实现简单
- ✅ 用户体验好（一次请求完成）

**缺点：**
- ❌ 服务器内存压力大（大文件夹会 OOM）
- ❌ 请求超时风险（大文件夹打包时间长）
- ❌ 并发能力差（每个请求占用大量资源）
- ❌ 无法显示进度

**适用场景：** 小文件夹（< 100MB，< 100 个文件）

---

### 方案 2：异步任务 + 后台打包（推荐）⭐

**流程：**
```
用户请求 → 创建打包任务 → 返回任务 ID
         ↓
    后台 Worker 异步处理：
    1. 查询文件列表
    2. 从 OSS 流式下载
    3. 边下载边压缩（不落盘）
    4. 上传到 OSS 临时目录
    5. 更新任务状态为"完成"
         ↓
用户轮询任务状态 → 任务完成后获取下载链接
```

**优点：**
- ✅ 不阻塞 API 请求
- ✅ 支持大文件夹
- ✅ 可以显示打包进度
- ✅ 失败可以重试
- ✅ 可以使用消息队列（RabbitMQ/Kafka）解耦

**缺点：**
- ❌ 实现复杂
- ❌ 需要额外的任务调度系统
- ❌ 用户体验稍差（需要等待）

**适用场景：** 大文件夹、生产环境

---

### 方案 3：客户端并行下载 + 本地打包（最优体验）

**流程：**
```
用户请求 → 服务器返回文件列表 + OSS 签名链接
         ↓
    客户端（浏览器/App）：
    1. 并行下载所有文件（使用 Web Workers）
    2. 本地打包成 ZIP（使用 JSZip）
    3. 触发浏览器下载
```

**优点：**
- ✅ 服务器压力最小
- ✅ 下载速度快（并行 + CDN）
- ✅ 可以显示详细进度
- ✅ 支持断点续传

**缺点：**
- ❌ 客户端内存压力（移动端不适用）
- ❌ 跨域问题（需要 CORS 配置）
- ❌ 浏览器兼容性

**适用场景：** PC 端 Web 应用

---

## 推荐方案：方案 2（异步任务）详细设计

### 1. 数据库表设计

```sql
CREATE TABLE `download_task` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `identity` varchar(36) NOT NULL COMMENT '任务唯一标识',
  `user_identity` varchar(36) NOT NULL COMMENT '用户标识',
  `folder_identity` varchar(36) NOT NULL COMMENT '文件夹标识',
  `folder_name` varchar(255) NOT NULL COMMENT '文件夹名称',
  `status` tinyint(4) NOT NULL DEFAULT '0' COMMENT '状态：0=待处理，1=处理中，2=完成，3=失败',
  `progress` int(11) DEFAULT '0' COMMENT '进度百分比（0-100）',
  `file_count` int(11) DEFAULT '0' COMMENT '文件总数',
  `processed_count` int(11) DEFAULT '0' COMMENT '已处理文件数',
  `zip_size` bigint(20) DEFAULT '0' COMMENT 'ZIP 文件大小（字节）',
  `zip_path` varchar(512) DEFAULT NULL COMMENT 'ZIP 文件 OSS 路径',
  `download_url` varchar(1024) DEFAULT NULL COMMENT '下载链接（带签名）',
  `error_msg` text COMMENT '错误信息',
  `expired_at` datetime DEFAULT NULL COMMENT '下载链接过期时间',
  `created_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP,
  `updated_at` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
  PRIMARY KEY (`id`),
  UNIQUE KEY `uk_identity` (`identity`),
  KEY `idx_user_identity` (`user_identity`),
  KEY `idx_status` (`status`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='文件夹下载任务表';
```

### 2. API 设计

#### 2.1 创建下载任务

```yaml
POST /api/file/folder/download/create
Authorization: Bearer <token>

Request:
{
  "folder_identity": "folder_abc123"  // 文件夹标识
}

Response:
{
  "task_identity": "task_xyz789",     // 任务 ID
  "status": 0,                        // 0=待处理
  "estimated_time": 30                // 预估时间（秒）
}
```

#### 2.2 查询任务状态

```yaml
GET /api/file/folder/download/status?task_identity=task_xyz789
Authorization: Bearer <token>

Response (处理中):
{
  "task_identity": "task_xyz789",
  "status": 1,                        // 1=处理中
  "progress": 45,                     // 进度 45%
  "file_count": 100,                  // 总文件数
  "processed_count": 45,              // 已处理 45 个
  "message": "正在打包文件..."
}

Response (完成):
{
  "task_identity": "task_xyz789",
  "status": 2,                        // 2=完成
  "progress": 100,
  "zip_size": 52428800,               // 50MB
  "download_url": "https://...",      // 下载链接（24小时有效）
  "expired_at": "2026-02-06T12:00:00Z"
}

Response (失败):
{
  "task_identity": "task_xyz789",
  "status": 3,                        // 3=失败
  "error_msg": "文件夹过大，超过 5GB 限制"
}
```

### 3. 核心代码实现

#### 3.1 创建任务（Handler）

```go
func (l *FolderDownloadCreateLogic) FolderDownloadCreate(req *types.FolderDownloadCreateRequest) (*types.FolderDownloadCreateResponse, error) {
    userIdentity := l.ctx.Value("user_identity").(string)
    
    // 1. 验证文件夹是否存在且属于用户
    folder := &models.UserRepository{}
    has, _ := l.svcCtx.DBEngine.
        Where("identity = ? AND user_identity = ?", req.FolderIdentity, userIdentity).
        Get(folder)
    if !has {
        return nil, errors.New("文件夹不存在")
    }
    
    // 2. 查询文件夹大小和文件数量（使用 CTE 递归）
    stats := l.getFolderStats(folder.Id, userIdentity)
    if stats.TotalSize > 5*1024*1024*1024 { // 5GB 限制
        return nil, errors.New("文件夹过大，超过 5GB 限制")
    }
    
    // 3. 创建下载任务
    task := &models.DownloadTask{
        Identity:       utils.UUID(),
        UserIdentity:   userIdentity,
        FolderIdentity: req.FolderIdentity,
        FolderName:     folder.Name,
        Status:         0, // 待处理
        FileCount:      stats.FileCount,
    }
    _, err := l.svcCtx.DBEngine.Insert(task)
    
    // 4. 发送到消息队列（异步处理）
    l.svcCtx.MQ.Publish("folder_download", task.Identity)
    
    return &types.FolderDownloadCreateResponse{
        TaskIdentity:  task.Identity,
        Status:        task.Status,
        EstimatedTime: stats.FileCount * 2, // 每个文件预估 2 秒
    }, nil
}
```

#### 3.2 后台 Worker（核心逻辑）

```go
func ProcessDownloadTask(taskIdentity string) error {
    // 1. 获取任务信息
    task := getTask(taskIdentity)
    updateTaskStatus(task.Identity, 1, "开始处理...")
    
    // 2. 递归查询所有文件
    files := getFilesRecursive(task.FolderIdentity, task.UserIdentity)
    
    // 3. 创建临时 ZIP 文件（流式写入）
    tempZip, _ := os.CreateTemp("", "download-*.zip")
    defer os.Remove(tempZip.Name())
    
    zipWriter := zip.NewWriter(tempZip)
    defer zipWriter.Close()
    
    // 4. 遍历文件，下载并添加到 ZIP
    for i, file := range files {
        // 从 OSS 流式下载
        ossReader := downloadFromOSS(file.Path)
        
        // 添加到 ZIP（保持目录结构）
        zipFile, _ := zipWriter.Create(file.RelativePath)
        io.Copy(zipFile, ossReader)
        ossReader.Close()
        
        // 更新进度
        progress := (i + 1) * 100 / len(files)
        updateTaskProgress(task.Identity, progress, i+1)
    }
    
    zipWriter.Close()
    
    // 5. 上传 ZIP 到 OSS 临时目录
    tempZip.Seek(0, 0)
    zipPath := fmt.Sprintf("temp/downloads/%s.zip", task.Identity)
    uploadToOSS(tempZip, zipPath)
    
    // 6. 生成带签名的下载链接（24小时有效）
    downloadURL := generateSignedURL(zipPath, 24*time.Hour)
    
    // 7. 更新任务状态为完成
    updateTaskComplete(task.Identity, downloadURL, tempZip.Size())
    
    return nil
}
```

#### 3.3 流式 ZIP 优化（避免 OOM）

```go
// 使用 io.Pipe 实现零拷贝
func streamZipToOSS(files []File, ossPath string) error {
    // 创建管道
    pr, pw := io.Pipe()
    
    // Goroutine 1: 写入 ZIP
    go func() {
        zipWriter := zip.NewWriter(pw)
        
        for _, file := range files {
            ossReader := downloadFromOSS(file.Path)
            zipFile, _ := zipWriter.Create(file.RelativePath)
            io.Copy(zipFile, ossReader)
            ossReader.Close()
        }
        
        zipWriter.Close()
        pw.Close()
    }()
    
    // Goroutine 2: 上传到 OSS（边生成边上传）
    return uploadToOSSStream(pr, ossPath)
}
```

### 4. 前端轮询示例

```javascript
async function downloadFolder(folderIdentity) {
  // 1. 创建任务
  const { task_identity } = await fetch('/api/file/folder/download/create', {
    method: 'POST',
    body: JSON.stringify({ folder_identity: folderIdentity })
  }).then(r => r.json());
  
  // 2. 显示进度条
  const progressBar = document.getElementById('progress');
  
  // 3. 轮询任务状态
  const interval = setInterval(async () => {
    const task = await fetch(`/api/file/folder/download/status?task_identity=${task_identity}`)
      .then(r => r.json());
    
    // 更新进度条
    progressBar.value = task.progress;
    progressBar.textContent = `${task.processed_count}/${task.file_count} 文件`;
    
    // 任务完成
    if (task.status === 2) {
      clearInterval(interval);
      // 自动下载
      window.location.href = task.download_url;
    }
    
    // 任务失败
    if (task.status === 3) {
      clearInterval(interval);
      alert('下载失败：' + task.error_msg);
    }
  }, 1000); // 每秒轮询一次
}
```

---

## 性能优化建议

### 1. 限制策略

```go
const (
    MaxFolderSize  = 5 * 1024 * 1024 * 1024  // 5GB
    MaxFileCount   = 1000                     // 最多 1000 个文件
    MaxConcurrent  = 10                       // 最多 10 个并发下载任务
    ZipExpiration  = 24 * time.Hour           // ZIP 文件 24 小时后删除
)
```

### 2. 并发控制

使用 Worker Pool 控制并发：

```go
type WorkerPool struct {
    tasks   chan string
    workers int
}

func (p *WorkerPool) Start() {
    for i := 0; i < p.workers; i++ {
        go func() {
            for taskID := range p.tasks {
                ProcessDownloadTask(taskID)
            }
        }()
    }
}
```

### 3. 缓存优化

- **任务结果缓存：** 相同文件夹 1 小时内重复下载，直接返回已生成的 ZIP
- **Redis 缓存：** 缓存任务状态，减少数据库查询

```go
cacheKey := fmt.Sprintf("download_task:%s:%s", userIdentity, folderIdentity)
if cached, _ := redis.Get(cacheKey); cached != "" {
    return cached // 返回缓存的下载链接
}
```

### 4. 定时清理

```go
// 定时任务：每天凌晨清理过期的 ZIP 文件
func CleanExpiredZips() {
    tasks := getExpiredTasks(time.Now().Add(-24 * time.Hour))
    for _, task := range tasks {
        deleteFromOSS(task.ZipPath)
        deleteTask(task.Identity)
    }
}
```

---

## 监控和告警

### 关键指标

1. **任务成功率：** `成功任务数 / 总任务数`
2. **平均处理时间：** 按文件数量分组统计
3. **失败原因分布：** OOM、超时、OSS 错误等
4. **并发任务数：** 实时监控 Worker 负载

### Prometheus 指标

```go
var (
    taskTotal = prometheus.NewCounterVec(
        prometheus.CounterOpts{Name: "download_task_total"},
        []string{"status"}, // success, failed
    )
    
    taskDuration = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{Name: "download_task_duration_seconds"},
        []string{"file_count_range"}, // 0-10, 10-50, 50-100, 100+
    )
)
```

---

## 总结

| 方案 | 复杂度 | 性能 | 用户体验 | 推荐场景 |
|------|--------|------|----------|----------|
| 同步打包 | ⭐ | ⭐ | ⭐⭐⭐ | 小文件夹（< 100MB） |
| 异步任务 | ⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐ | **生产环境（推荐）** |
| 客户端打包 | ⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐ | PC Web 应用 |

**最终推荐：** 方案 2（异步任务）+ 方案 3（客户端打包）结合
- 小文件夹（< 50MB）：客户端打包
- 大文件夹（> 50MB）：服务器异步打包

---

## 参考资料

- [Go ZIP 库文档](https://pkg.go.dev/archive/zip)
- [阿里云 OSS 流式上传](https://help.aliyun.com/document_detail/88434.html)
- [JSZip 客户端打包](https://stuk.github.io/jszip/)
- [RabbitMQ Go 客户端](https://github.com/rabbitmq/amqp091-go)
